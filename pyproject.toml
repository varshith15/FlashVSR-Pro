[project]
name = "flashvsr-pro"
version = "0.1.0"
description = "FlashVSR Pro plugin for Daydream Scope"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "torch==2.9.1",
    "torchvision==0.24.1",
    "torchaudio==2.9.1",
    "torchmetrics",
    "torchsde",
    "accelerate>=1.1.1",
    "einops>=0.8.1",
    "huggingface-hub>=0.25.0",
    "matplotlib==3.10.3",
    "numpy==1.26.4",
    "opencv-python==4.11.0.86",
    "opencv-python-headless==4.11.0.86",
    "peft>=0.17.1",
    "pillow==11.0.0",
    "safetensors>=0.6.2",
    "sentencepiece==0.2.0",
    "transformers>=4.49.0",
    "pytorch-lightning==2.5.2",
    "imageio==2.37.0",
    "imageio-ffmpeg==0.6.0",
    "protobuf==3.20.3",
    "ftfy>=6.3.1",
    "pandas==2.3.0",
    "tqdm",
    "datasets",
    "ffmpeg-python",
    "modelscope",
    "block-sparse-attn",
    "aiortc>=1.13.0",
    "fastapi>=0.116.1",
    "httpx>=0.28.1",
    "twilio>=9.8.0",
    "uvicorn>=0.35.0",
    "easydict>=1.13",
    "diffusers>=0.31.0",
    "lmdb>=1.7.3",
    "omegaconf>=2.3.0",
    "flash-attn==2.8.3; sys_platform == 'linux' or sys_platform == 'win32'",
    "sageattention==2.2.0; sys_platform == 'linux' or sys_platform == 'win32'",
    "pluggy>=1.5.0",
    "click>=8.3.1",
    "torchao==0.15.0",
    "kernels>=0.10.4",
    "triton==3.5.1; sys_platform == 'linux'",
    "triton-windows==3.5.1.post24; sys_platform == 'win32'",
    "SpoutGL>=0.1.1; sys_platform == 'win32'",
    "PyOpenGL>=3.1.10; sys_platform == 'win32'",
]

[project.entry-points.scope]
flashvsr = "scope"

[tool.uv]
preview = true
override-dependencies = [
    "torch==2.9.1",
    "torchvision==0.24.1",
    "torchaudio==2.9.1",
    "nvidia-cudnn-cu12>=9.15",
]

[tool.uv.extra-build-dependencies]
flash-attn = [{ requirement = "torch", match-runtime = true, marker = "sys_platform == 'linux' or sys_platform == 'win32'" }]
block-sparse-attn = ["torch==2.9.1"]

[tool.uv.extra-build-variables]
flash-attn = { FLASH_ATTENTION_SKIP_CUDA_BUILD = "TRUE" }

[tool.uv.sources]
torch = [
    { index = "pytorch-cu128", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchvision = [
    { index = "pytorch-cu128", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
flash-attn = [
    # Prebuilt Linux wheels from https://github.com/Dao-AILab/flash-attention
    { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.9cxx11abiTRUE-cp312-cp312-linux_x86_64.whl", marker = "sys_platform == 'linux'" },
    # Prebuilt Windows wheels from https://github.com/kingbri1/flash-attention
    { url = "https://github.com/kingbri1/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu128torch2.9.0cxx11abiFALSE-cp312-cp312-win_amd64.whl", marker = "sys_platform == 'win32'" },
]
sageattention = [
    # Prebuilt Linux wheels from https://huggingface.co/Kijai/PrecompiledWheels
    { url = "https://huggingface.co/Kijai/PrecompiledWheels/resolve/main/sageattention-2.2.0-cp312-cp312-linux_x86_64.whl", marker = "sys_platform == 'linux'" },
    # Prebuilt Windows wheels from https://github.com/woct0rdho/SageAttention/releases
    { url = "https://github.com/woct0rdho/SageAttention/releases/download/v2.2.0-windows.post4/sageattention-2.2.0+cu128torch2.9.0andhigher.post4-cp39-abi3-win_amd64.whl", marker = "sys_platform == 'win32'" },
]
block-sparse-attn = { path = "./Block-Sparse-Attention" }

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.setuptools.packages.find]
where = ["."]
include = ["diffsynth*", "utils*", "scope*"]
namespaces = false

[tool.setuptools.package-dir]
scope = "scope"
